- Abstract Patterns and Features
	- Features
		- type
			- Raw quantitive data
				- numerical data, boolean values, vectors, and even images
			- Direct features
				- Edge detection, detected circles/ellipses, Spectrograms
			- Abstract features
				- Region textures, **Moments**
		- problem
			- insufficient training data
			- unrepresentative training data
			- irrelevant features
			- poor quality data
	- Abstract features: Moments
		- Calculating Moments
			- ![[Screenshot 2568-02-01 at 13.34.45.png]]
			- m = moment
			- $moment_{pq}$ the $pq^{th}$ moment
			- x,y = pixel
		- normalized moment
			- ![[Screenshot 2568-02-01 at 13.57.55.png]]
- Classification and trees
	- Classification
		- supervised learning
		- predict any categorical - multiple-choice target feature
	- Data preparation
		- Splitting data into train set and test set
		- Data Cleaning/ imputation
			- `np.nan` or `pd.NA` --> filled or dropping
			- duplication --> dropping or keeping
		- Data preparation
			- Categorical values -> encode, one-hot encoding, some algorithms
			- Scaling/Standardisation of numerical features (PCA, SVM)
			- for undersampling or oversampling -> imbalanced learn package
		- Pipelines
			- composed by a sequence of transformers that transform the input for the next transformer or for the final predictor
			- used for easily repeated and tuned
	- Scikit-learn (sklearn) design
		- estimators
			- `fit()` for supervised learning
			- `set_params()` and `get_params()` how to know and set the hyperparameters 
		- transformers
			- `transform(x)`: e.g., like using `pca.fit(x)` and `fit_transform()`
		- predictors: `predict(x)`, provide predictions from observations  
		- pipeline
			- a set of transformers and a final predictor
			- `pipeline.fit(x)`: invoke transformation step
			- `pinpeline.predict(x)`: invoke transformation on each step and predict on the final predictor
	- classification algorithm 
		- binary algorithms 
			- Support Vector Machine (SVM)
			- Logistic Regression
			- Stochastic Gradient Descent
		- Multiclass algorithms
			- Naive Bayes
			- Decision Tree
		** binary algorithms can be useful for multiclass problems with M label
		- one-vs-one strategy
			- distinguish every couple of labels
			- M(M-1)/2 -> N/M**2
		- one-vs-all strategy
			- distinguish class from non-class
			- predictors, each trained on a full dataset
	- model evaluation
		- how good is the resulting model
		- overfitting or not
			- overfitting and underfitting
				- overfitting -> It memorizes the training set and is not good at generalizing to new inputs
				- underfitting -> not powerful enough to learn/explain the training data (low training accuracy)
			- increasing the model complexity by reducing bias and increasing variance, called bias-variance tradeoff
			- hyperparameters and cross-validation
				- e.g., in decision tree models, fix a maximum depth or number of leaves
				- hyperparameter should be evaluated using a portion of the training dataset called the validation set
		- Metrics
		
				| | Predicted Yes | Predicted No |
				| - | - | - |
				| **Actual Yes** (TP + FN) | 50 (TP) | 10 (FN) |
				| **Actual No** (FP + TN) | 5 (FP) | 35 (TN) |

			- binary classifier accuracy = (TP + TN) / (TP + TN + FP + FN)
			- precision = TP / (TP + FP)
			- Recall: 
				- For positive class (Sensitivity) = TP / (TP + FN)
				- For negative class (Sensitivity) = TN / (TN + FP)
			- F1 score: TP / (TP + (FP + FN) / 2)
	- Decision Trees
		- idea: recursively split dataset on an attribute-condition-value -> ensemble
	- Ensemble models
		- aggregating multiple trained models to improve predictions![[Screenshot 2568-02-01 at 18.02.04.png]]
			- voting classifier 
			- average model irregularities -> decrease variance, reduce overfitting
			- parallelize train
			- example:
				- `VotingClassifier`
				- `BaggingClassifier` for patches and subspaces
				- `RandomForest`: random patches with decision trees
				- `Boosting`: Train predictors sequentially
				- `Adaboost`: increase the weight of misclassified instances, uniform weights
				- `Gradient Tree Boosting`
	- Convolutional Neural Networks (CNN)
		- Convolutional layer ![[Screenshot 2568-02-01 at 18.19.18.png]]
			- 1 Dimensional ![[Screenshot 2568-02-01 at 18.19.28.png]]
			- 2 Dimensional ![[Screenshot 2568-02-01 at 18.20.56.png]] ![[Screenshot 2568-02-01 at 18.21.16.png]]
			- Pooling Layer
				- Max Pooling![[Screenshot 2568-02-01 at 18.22.05.png]]![[Screenshot 2568-02-01 at 18.22.30.png]]
		- ![[Screenshot 2568-02-01 at 18.23.12.png]]
		- ![[Screenshot 2568-02-01 at 18.23.35.png]]
		- ![[Screenshot 2568-02-01 at 18.23.52.png]]
		- ![[Screenshot 2568-02-01 at 18.24.05.png]]![[Screenshot 2568-02-01 at 18.24.55.png]]![[Screenshot 2568-02-01 at 18.25.03.png]]![[Screenshot 2568-02-01 at 18.25.36.png]]
- Reinforcement Learning
	- 5 elements
		- Environments
			- Farama Gymnasium = OpenAI Gym
				- a collection of simulations and environments
				- to simulate step by step whilst connecting to an agent
				- hug variety
				- use a tabular-based Q-learning
					- Q-learning
						- **a reinforcement learning algorithm that finds an optimal action-selection policy for any finite Markov decision process (MDP)** 
						- A Markov model is ==a stochastic model that describes a sequence of events where the probability of each event depends on the previous event==. It's used in probability theory, statistics, and decision analysis
							- Applications e.g.,
								- **Weather**
								    A Markov model can be used to predict the weather, for example, by modeling the probability of a sunny day being followed by another sunny day. 
								- **Healthcare**
								    A Markov model can be used to model the health of patients over time, including the progression of disease and the effects of medical interventions. 
						- Q-Table
							- States ($S_t$) with Q-Value
								- Q-Value: showing that the algorithm thinks it would be the best decision
						- Update Formula ![[Screenshot 2568-02-10 at 10.21.21.png]]
						- utilise epsilon-_greedy Q-learning_, a well-known reinforcement learning algorithm
						- (SARSA) State-Action-Reward-State-Action
				- cr. https://gymnasium.farama.org/introduction/basic_usage/
		- States ($S_t$) - the current state of the scenario (a value or array of value) 
		- Actions ($A_t$) - An array representing some forces to be applied in the simulation
		- Rewards ($R_t$) - A value representing how the system performed
		- Agents - The system that reads the states
	- Policies -  set the observation space, action space, and reward.
	- Basic Neural Network
	- Credit assignment -  every task of agent has reward and reduction. 
- Genetic algorithms (GA) and Neuroevolution
	- fitness function - measuring the quality of each solution
	- method
		- Selection
			- Roulette-whee;
			- Tournament-based
			- Truncation
		- Replication
			- One-point crossover
			- Multipoint crossover
			- Uniform crossover
		- Mutation
		- Elitism
	- Applying GA to NN for 
		- evolving NN weights
		- alternative to backpropagation based on gradients
			- backpropagation - technique of train
			- gradient range of environment
	- NeuroEvolution of Augmenting Topologies (NEAT), used for 
		- is an evolutionary algorithm that creates artificial neural networks.
		- Method
			- encoding
				- Mutation - weight mutation
					- ![[Screenshot 2568-02-10 at 10.42.15.png]]![[Screenshot 2568-02-10 at 10.42.31.png]]
			- Crossover
				- First of all, we need to select a dominant parent. This is the parent that will specify the structure of the child's network.
				- Secondly, we find all of the connections shared by both parents. You’d think this would be difficult, but since we have innovation numbers, we can just take each connection whose innovation number appears in both parent networks.
				- For any connection shared by both parents, we randomly give the child one of the connections. This ensures that the weights of any shared connection in the child network will randomly come from either parent.
				- Finally, for any connections not shared by both networks, the child inherits them from the dominant parent.
				- ![[Screenshot 2568-02-10 at 10.44.06.png]]
			- Niching
				- how to manage the evolution of topologies and weights at the same time
				- defending the compatibility threshold by $c_1 \triangle{G} + x_2 \triangle{W}$, Average of G and Average of W
- Scalability and parallelism
	- Reason
		- Training ML Take time - large training
		- reduce cost and time
		- improve scalability
	- method
		- Hyperparameter search, also parallelisable
			- early stop poor configurations
		- Successive halving (sha)
			- to distinguish the good candidates from the bad
			- iteration $k=log_2 ⌊R∕r⌋$ when
				- R(max_resources): resources that would be used to train one candidate if SHA would not be used
				- r(min_resources): minimum resources that could be used to distinguish good candidates from bad ones
			- cost 
				- •N≥R/r so the biggest saving is for  R∕r=N for which ∆ =〖log〗_2⁡N∕N and R_tot^∗=R 〖log〗_2⁡N
			- time
				- •SHA is sequential so time $T=Ntime(r)+N/2 time(2r)+…=N∗∑2_(i=1)^log_2⁡〖R∕r〗* time(i∗r_i )/i$
			- 2 kinds
				- Synchronous SHA: Split the n_i cadidates of each iteration across m workers; this could be faster than the
				- Asynchronous SHA: •Assign to each free worker one candidate to run, for iteration i (if nothing to run, create a new candidate to run in iteration i=0)
		- •Idea: find in which direction to update the weights to reduce the error (loss) of the network 
			- $L_D (w)=∑_{(x,y)∈D}〖L_{(x,y)} (w) 〗$  We want to compute the gradient of the loss with respect to each weight $∂L/(∂w_{jk}^l )$
		- Backpropagation (Gradient descent)
			- •(Mini-batch) Stochastic Gradient Descent (SGD)
		- Parallel Training Models
			- Partition the model (weights) across nodes
			- ![[Screenshot 2568-02-13 at 12.50.32.png]]![[Screenshot 2568-02-13 at 12.50.39.png]]
			- •Data parallelism: Partition the data across nodes
				- Ensemble approach: each node train a full replica of the model on the  local partition, then use soft/hard voting during inference
			- Parallel SGD
				- weights stored in main memory in case of multicore/GPUs workers or a  parameter server if training is distributed over multiple machines
				- workers get the current weights then compute gradients of weights based on local data
		- Summary
			- Two most time-consuming factors in ML training
				- Hyperparameter Optimisation (i.e., training many ML models)
				- Backpropagation (when training NN on big datasets) 
			- Two ways to reduce these training cost and thus increase scalability
				- Successive Halving (SHA) approximates the quality of a model using a lower-fidelity model (less data or simpler model)
				- Stochastic/Mini-batch Gradient Descent approximate the gradient using a sample
			- Ways to obtain results faster by parallelising computation on multiple worker nodes
				- Parallel SHA (Synch or Asynch) reduces the time to find hyper-parameters
				- Parallel SGD (Synch/Asynch or Local) reduces the time to complete training
	- Future
		- AI in Industry
			- bakeries
			- cancer
			- healthcase 
				- hearing loss
				- eeg analysis -> dream reconstruction
			- Reinforcement learning 
				- NEAT
					- multi agent interaction
			- conputational creativity
			- deep fakes
			- 