{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_SLMzgGIpjE"
   },
   "source": [
    "Advanced Convolutional Neural Networks (CNNs) with CIFAR-10 dataset\n",
    "=========\n",
    "\n",
    "In this tutorial we will learn how to use more complex CNNs, showing that the training of a __deeper__ CNN can improve the performance of the model. We will also explore the concept of __data augmentation__ to understand how to increase the variability of the training set by, for example, rotating the original images to generate new training stimuli.\n",
    "\n",
    "This tutorail will use the CIFAR-10 training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKafL_SXIpjI"
   },
   "source": [
    "**CNN for CIFAR-10**\n",
    "\n",
    "To work with more complex CNNs, we will now use a more complex training dataset called __CIFAR-10__. https://www.cs.toronto.edu/~kriz/cifar.html . CIFAR-10 is a benchamark machine learning set of low-resolution, colour images. It includes 60000 32x32 colour (using 3 RGB colour channels) images in these 10 classes of objects: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. Each class has 6000. There are 50000 training images and 10000 test images. This dataset is enclosed in the default Anaconda KERAS package. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSw16YYkIpjK"
   },
   "source": [
    "**Initialisation of the program**\n",
    "\n",
    "The program starts with the importing of typical Keras and other Python service modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x595vK3pIpjN",
    "outputId": "0b598400-30e9-4f17-d9eb-a1357a6d43d8"
   },
   "outputs": [],
   "source": [
    "# importing of modules for CIFAR-10 CNN\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "\n",
    "# importing of service libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wx5--x5hIpjV"
   },
   "source": [
    "The following constant and variable definitions are needed for the network and training parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1SvoRcMIpjX",
    "outputId": "85c3179d-88bb-45f3-fb7d-97767a9a5135"
   },
   "outputs": [],
   "source": [
    "#training constants\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCH = 20 # use 20 for best initial results\n",
    "N_CLASSES = 10\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT = 0.2\n",
    "OPTIM = RMSprop()\n",
    "\n",
    "print('Main variables initialised.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpuekS__Ipjd"
   },
   "source": [
    "Constant definition for the training set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWaibn5BIpje",
    "outputId": "e016668b-42a3-42ff-f93e-cb0a403df4fc"
   },
   "outputs": [],
   "source": [
    "# CIFAR_10 is a set of 60K images 32x32 pixels on 3 channels\n",
    "IMG_CHANNELS = 3\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "\n",
    "print('Image variables initialisation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcOhLgJ8Ipjk"
   },
   "source": [
    "__CIFAR-10 data loading and processing__\n",
    "\n",
    "Loading and preparation of the CIFAR-10 training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVzGwn80Ipjm",
    "outputId": "ad6c4e65-a990-4953-e24e-7abf535611bc"
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "(input_X_train, output_y_train), (input_X_test, output_y_test) = cifar10.load_data()\n",
    "print('input_X_train shape:', input_X_train.shape)\n",
    "print(input_X_train.shape[0], 'train samples')\n",
    "print(input_X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical\n",
    "output_Y_train = utils.to_categorical(output_y_train, N_CLASSES)\n",
    "output_Y_test = utils.to_categorical(output_y_test, N_CLASSES)\n",
    "\n",
    "# float and normalization\n",
    "input_X_train = input_X_train.astype('float32')\n",
    "input_X_test = input_X_test.astype('float32')\n",
    "input_X_train /= 255\n",
    "input_X_test /= 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6_L0SrmIpjr"
   },
   "source": [
    "**Visualisation of two sample CIFAR-10 images**\n",
    "\n",
    "Here we will visualise two sample images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U2gu1BhgIpjs",
    "outputId": "0fc3ca4a-a417-4b62-d9b5-9fc0043154a2"
   },
   "outputs": [],
   "source": [
    "# visualisation of the numerical vector and 2D colour plot of the sample CIFAR imnage 2\n",
    "Selected_Image = 2\n",
    "image = input_X_train[Selected_Image]\n",
    "print (\"Sample input image: \" + str(image))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "Selected_Image = 3\n",
    "image = input_X_train[Selected_Image]\n",
    "print (\"Sample input image: \" + str(image))\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTUkz65eIpjx"
   },
   "source": [
    "**Simple CNN model definition**\n",
    "\n",
    "This code defines a simple CNN network.\n",
    "The model will learn 32 convolutional filters, each of a 3 x 3 size. The output dimension is the same one of the input shape, with a 32 x 32 filters (default stride of 1 is used). The activation function ReLU will be used. \n",
    "The network then has a max-pooling layer with pool size 2 x 2, and a dropout at 25%.\n",
    "\n",
    "The next level of depth has a dense layer with 512 units and ReLU activation, followed by a dropout at 50%.\n",
    "Finally, a softmax layer is used with 10 units/classes as output, i.e. one for each of the 10 classes of objects encoded with one-hot coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAWZ0UKzIpjz",
    "outputId": "9ed52e7f-f17b-48cc-daca-2dddd99aa6d7"
   },
   "outputs": [],
   "source": [
    "# network definition\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(N_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print('CNN network definition.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8B4dEyVIpj2"
   },
   "source": [
    "**Model compilation**\n",
    "\n",
    "This compiles the CNN model, and then shows its summary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rLrhT0HSIpj4",
    "outputId": "4d0c9dca-3813-4306-e7a9-23487de28b30",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAJPemJyIpj9"
   },
   "source": [
    "**Training of the CNN**\n",
    "\n",
    "This line of code trains the model, saving the results in the history variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9K5fqdXIpj-",
    "outputId": "9b8b6e93-812e-4146-ff09-1c3bc058590d"
   },
   "outputs": [],
   "source": [
    "# training/fitting of the DNN model\n",
    "\n",
    "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, validation_split=VALIDATION_SPLIT,  verbose=VERBOSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-kbN3RlIpkD"
   },
   "source": [
    "**Saving of the model and of the trained weights**\n",
    "\n",
    "This saves the model definition and the weights, after training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z57S_sTRIpkF",
    "outputId": "80205c50-105e-4e48-c138-946d1ccdbaf8"
   },
   "outputs": [],
   "source": [
    "#save model in json format into a file\n",
    "model_json = model.to_json()\n",
    "open('cifar10_architecture.json', 'w').write(model_json)\n",
    "\n",
    "#save the trained weights\n",
    "model.save_weights('cifar10.weights.h5', overwrite=True)\n",
    "\n",
    "print('Files saved for model definition and for weights.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GvXVkx1IpkJ"
   },
   "source": [
    "**Analysis of the results**\n",
    "\n",
    "This code generates the test scores, so we can visualise and inspect the model's peformance.\n",
    "\n",
    "It also plots the accuracy and loss values along the training timescale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "id": "N2XtixmtIpkL",
    "outputId": "52c6ca65-2b74-4f7d-9e26-3e8beda435a0"
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "score = model.evaluate(input_X_test, output_Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score/loss:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "#plt.plot(mo)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1o9i5nqDIpkO"
   },
   "source": [
    "A deeper CNN\n",
    "-------------\n",
    "\n",
    "To improve the performance of the network on the CIFAR-10 dataset, it is possible to use a deeper CNN, with a chain of multiple convolution and pooling layers.\n",
    "The following network will be used:\n",
    "\n",
    "conv+conv+maxpool+dropout+conv+conv+maxpool\n",
    "\n",
    "The final classification layers will use the standard:\n",
    "\n",
    "dense+dropout+dense\n",
    "\n",
    "All the layers will use the reLu function, except the final one with the Softmax function necessary for the categorical classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VmaK6n4AIpkP",
    "outputId": "63915ee5-1d00-4867-d78e-e11999ac4452"
   },
   "outputs": [],
   "source": [
    "# REUSE THE SAME INITIALISATION CODE AND THE TRAINING AND TEST DATA SET LOADING OPERATION\n",
    "\n",
    "N_EPOCH = 40 # bigger network will benefit from extra training epochs\n",
    "\n",
    "# Complex DNN model definition\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same', input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(N_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# OPTIM = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "OPTIM = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'], run_eagerly=True)\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_WU_cUNkmr-"
   },
   "source": [
    "**Training of the deeper CNN**\n",
    "\n",
    "Let's train (fit) this new model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctRJSHkVkmr_",
    "outputId": "b3dd07ba-58b5-4b4c-e6e3-bf79c17d3228"
   },
   "outputs": [],
   "source": [
    "# training/fitting of the complex DNN model\n",
    "history = model.fit(input_X_train, output_Y_train, batch_size=BATCH_SIZE, epochs=N_EPOCH, validation_split=VALIDATION_SPLIT,  verbose=VERBOSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhkax6pXIpkT"
   },
   "source": [
    "**Analysis of the Deeper CNN results**\n",
    "\n",
    "This generates the test scores and plots for the new, deeper DNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "id": "FfRvK-lUIpkU",
    "outputId": "7586268f-5818-4746-81ef-927efc275c44"
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "score = model.evaluate(input_X_test, output_Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score/loss:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "#plt.plot(mo)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-Mzs-L7IpkZ"
   },
   "source": [
    "Data Augmentation\n",
    "-------------\n",
    "\n",
    "To further improve the performance of the model, it is advisable to use a larger training set, to expose the network to more variations of the images.\n",
    "One way to achieve this, without having to collect new images from the real world, is to __augment__ the existing images with multiple types of transformations of the dataset stimuli. This can include rotation of the image, rescaling, horizontal/vertical flip, zooming, channel shift, etc.\n",
    "\n",
    "Below is an example of the code that augments the current datase.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-85_nYLXIpkZ",
    "outputId": "2453682f-360b-4fb0-9059-b6fdf2328b93"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from keras.datasets import cifar10\n",
    "\n",
    "#load dataset\n",
    "#(input_X_train, output_y_train), (input_X_test, output_y_test) = cifar10.load_data()\n",
    "\n",
    "# augumenting\n",
    "print(\"Augmenting training set images...\")\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "   rotation_range=40,\n",
    "   width_shift_range=0.2,\n",
    "   height_shift_range=0.2,\n",
    "   zoom_range=0.2,\n",
    "   horizontal_flip=True,\n",
    "   fill_mode='nearest')\n",
    "\n",
    "# rotation_range is a value in degrees (0 - 180) for randomly rotating pictures\n",
    "# width_shift and height_shift are ranges for randomly translating pictures vertically or horizontally\n",
    "# zoom_range is for randomly zooming pictures\n",
    "# horizontal_flip is for randomly flipping the images horizontally\n",
    "# fill_mode fills in new pixels that can appear after a rotation or a shift\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWIpifR4Ipkc"
   },
   "source": [
    "__Training with augmented data__\n",
    "\n",
    "The function below used the dynamic generation of the augmented data during the training (just in time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kd_JgZM9Ipkd",
    "outputId": "e75ca9f2-b69f-4fa6-d3dd-f895adad8af6"
   },
   "outputs": [],
   "source": [
    "\n",
    "#fit the dataset\n",
    "datagen.fit(input_X_train)\n",
    "\n",
    "\n",
    "# train by fitting the model on batches with real-time data augmentation\n",
    "history = model.fit_generator(datagen.flow(input_X_train, output_Y_train, batch_size=BATCH_SIZE), steps_per_epoch=input_X_train.shape[0], epochs=N_EPOCH, verbose=VERBOSE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0ZLORlPIpkh"
   },
   "source": [
    "**Analysis of the Data Augmented, Deeper CNN results**\n",
    "\n",
    "This generates the test scores and plots for the deeper DNN trained on the augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "id": "BxZG9aM2Ipki",
    "outputId": "2c9c392e-1ee8-4485-bb92-252c23cad703"
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "score = model.evaluate(input_X_test, output_Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
    "print(\"\\nTest score/loss:\", score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "#plt.plot(mo)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Bwi-kLYIpkl"
   },
   "source": [
    "Below is a commented different example of a data augmentation approach. \n",
    "\n",
    "But we have carried out plenty of slow, long simulations for this class, and we can stop here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_JAWfc4Ipkm"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(input_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouCjBST_Ipkq"
   },
   "source": [
    "Conclusions\n",
    "-------------\n",
    "\n",
    "Today we learned to train more complex DNNs, and to use data augmentation to further improve the network training and performance.\n",
    "\n",
    "**Copyright (c)** 2022 Angelo Cangelosi, MIT License. Code and examples adapted from Gulli & Pal (2017) Deep Learning with Kera. Punkt Publishing. With support from Wenjie Huang."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DATA70132_Lab6b_Keras_CNN_CIFAR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
