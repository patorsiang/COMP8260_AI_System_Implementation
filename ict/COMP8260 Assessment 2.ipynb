{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# COMP8260 Assessed Class 2 #\n",
    "\n",
    "The following assessment asks a series of questions based on the structure of Convolutional Neural Networks.\n",
    "\n",
    "Answer each by modifying the code or asnwering the question asked.\n",
    "\n",
    "You may need to consult the Keras reference at https://keras.io/api/ for ideas for suitable answers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Q1 #\n",
    "\n",
    "Examine the following skeleton definition of a CNN in Keras similar to that employed in Class 3\n",
    "\n",
    "Fill in the missing sections to define a convolutional neural network with the following configuration\n",
    "\n",
    "- Two convolutional layers with 8 and 16 filters respectively, a kernel size of 5 and rectivied linear activation.\n",
    "\n",
    "- One Max pooling layer with a pool size of 2. Place this at an appropriate position with the network.\n",
    "\n",
    "- One filly connected layer with 10 outputs and \"softmax\" activation.\n",
    "\n",
    "- One other type of layer is required within this configuration. Identify what it should be and place it at an appropraite position in the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 15:46:46.491023: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-04 15:46:46.491261: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-04 15:46:46.491512: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-04 15:46:49.999231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(8,  (5, 5), activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(16,  (5, 5), activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Displaying the model's summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 24, 24, 8)         208       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 8)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 16)          3216      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13674 (53.41 KB)\n",
      "Trainable params: 13674 (53.41 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Q2 #\n",
    "\n",
    "Provide suitable configurations to compile the model in Q1 using an optimiser and an error calculation. \n",
    "- ensure you use a different, though still appropriate, optimiser that the \"adam\" optimiser used in Class 3.\n",
    "- choose an appropraite error (\"loss\") function.\n",
    "\n",
    "- train the network for 10 epochs with a suitable batch size.\n",
    "\n",
    "Note: You should not modify `train_images`, `train_labels`, `test_images`, or `test_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 24s 12ms/step - loss: 0.1805 - accuracy: 0.9474\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0629 - accuracy: 0.9805\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0456 - accuracy: 0.9859\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0359 - accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0294 - accuracy: 0.9911\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.0249 - accuracy: 0.9921\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0212 - accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0173 - accuracy: 0.9943\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0151 - accuracy: 0.9952\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0136 - accuracy: 0.9955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f20144927a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# Do not modify the lines of this cell above this comment.\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Evaluating the convnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 7ms/step - loss: 0.0374 - accuracy: 0.9898\n",
      "Test accuracy: 0.990\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 #\n",
    "\n",
    "Difine a fully connected network for the following input with:\n",
    "\n",
    "- four layers \n",
    "- a suitable number of units in each layer\n",
    "- a suitable activation function for each layer bearing in mind these may not be the same for each layer. Do not use the sigmoid activation as was used in class 3. Select other suitable alternatives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 784)               615440    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 784)               615440    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1238730 (4.73 MB)\n",
      "Trainable params: 1238730 (4.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(28, 28, 1)) # 28 x 28 grey scaled images\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(784, activation=\"relu\")(x)\n",
    "x = layers.Dense(784, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 #\n",
    "\n",
    "Provide suitable Keras statements to compile and train the network defined in Q3 but choosing a different optimiser than that employed in class 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0872 - accuracy: 0.9729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1fec7033a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5 #\n",
    "\n",
    "Explain how two fully connected layers may be used to implement non-linear decision functions. Can two layers be used to implement arbitrary decision functions? If not, what restrictions remain on the type of decision function which may be implemented?\n",
    "\n",
    "Explain what is meant by Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5 Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two fully connected layers can implement a non-linear decision function because the first layer applies a linear transformation, and the activation function introduces non-linearity. However, two layers alone may not fully capture complex patterns or hierarchical features in high-dimensional data. While the Universal Approximation Theorem states that a single hidden layer can approximate any function, the feature extraction process may be inefficient with only two layers. In some cases, deeper architectures or specialized layers (such as convolutional layers) are needed for better generalization and representation learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter08_intro-to-dl-for-computer-vision.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
