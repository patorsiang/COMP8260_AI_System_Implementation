{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b06ef21",
   "metadata": {},
   "source": [
    "# COMP8260 - AI Systems Class 2\n",
    "### Full Jupyter Notebook Solution (Tasks 1-17)\n",
    "\n",
    "This notebook provides structured solutions to **all tasks (1-17)** from the class document. Each task includes explanations, implementation, and table comparisons where needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9d613c",
   "metadata": {},
   "source": [
    "## Task 1: Load and Explore the Dataset\n",
    "We load the **Adult Dataset** from `openml.org` using `fetch_openml`. The dataset contains **demographic and employment information**, and we aim to predict whether a person earns `<=50K` or `>50K` per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fa0350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   age             48842 non-null  int64   \n",
      " 1   workclass       46043 non-null  category\n",
      " 2   fnlwgt          48842 non-null  int64   \n",
      " 3   education       48842 non-null  category\n",
      " 4   education-num   48842 non-null  int64   \n",
      " 5   marital-status  48842 non-null  category\n",
      " 6   occupation      46033 non-null  category\n",
      " 7   relationship    48842 non-null  category\n",
      " 8   race            48842 non-null  category\n",
      " 9   sex             48842 non-null  category\n",
      " 10  capital-gain    48842 non-null  int64   \n",
      " 11  capital-loss    48842 non-null  int64   \n",
      " 12  hours-per-week  48842 non-null  int64   \n",
      " 13  native-country  47985 non-null  category\n",
      "dtypes: category(8), int64(6)\n",
      "memory usage: 2.6 MB\n",
      "None\n",
      "\n",
      "Missing values per column:\n",
      "age                  0\n",
      "workclass         2799\n",
      "fnlwgt               0\n",
      "education            0\n",
      "education-num        0\n",
      "marital-status       0\n",
      "occupation        2809\n",
      "relationship         0\n",
      "race                 0\n",
      "sex                  0\n",
      "capital-gain         0\n",
      "capital-loss         0\n",
      "hours-per-week       0\n",
      "native-country     857\n",
      "dtype: int64\n",
      "\n",
      "Dataset Shape: (48842, 14)\n",
      "\n",
      "Target Distribution:\n",
      "class\n",
      "<=50K    37155\n",
      ">50K     11687\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "dataset = fetch_openml(data_id=1590, as_frame=True)\n",
    "\n",
    "# Extract features and target\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "# Display basic info\n",
    "print(\"Dataset Info:\")\n",
    "print(X.info())\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Check dataset size\n",
    "print(\"\\nDataset Shape:\", X.shape)\n",
    "\n",
    "# Target class distribution\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b781f",
   "metadata": {},
   "source": [
    "## Task 2: Split Data into Training and Testing Sets\n",
    "We split the dataset into **80% training** and **20% testing** using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515b4e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: (39073, 14)\n",
      "Testing Set Shape: (9769, 14)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display shapes\n",
    "print(\"Training Set Shape:\", X_train.shape)\n",
    "print(\"Testing Set Shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c39a63b",
   "metadata": {},
   "source": [
    "## Task 3: Extract Numerical Features\n",
    "We select only the **numerical columns** for our first Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4170e6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_num Shape: (39073, 6)\n",
      "X_test_num Shape: (9769, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select numerical features\n",
    "X_train_num = X_train.select_dtypes(include=['int64', 'float64'])\n",
    "X_test_num = X_test.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Display shapes\n",
    "print(\"X_train_num Shape:\", X_train_num.shape)\n",
    "print(\"X_test_num Shape:\", X_test_num.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1b910",
   "metadata": {},
   "source": [
    "## Task 4: Train a Decision Tree Classifier on Numerical Data\n",
    "We train a `DecisionTreeClassifier` using only numerical features and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79b1e1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9986691577304021\n",
      "Testing Accuracy: 0.7714197973180469\n",
      "Tree Depth: 52\n",
      "Number of Leaves: 7857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train Decision Tree\n",
    "clf_num = DecisionTreeClassifier(random_state=42)\n",
    "clf_num.fit(X_train_num, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_accuracy_num = accuracy_score(y_train, clf_num.predict(X_train_num))\n",
    "test_accuracy_num = accuracy_score(y_test, clf_num.predict(X_test_num))\n",
    "\n",
    "# Print results\n",
    "print(\"Training Accuracy:\", train_accuracy_num)\n",
    "print(\"Testing Accuracy:\", test_accuracy_num)\n",
    "print(\"Tree Depth:\", clf_num.get_depth())\n",
    "print(\"Number of Leaves:\", clf_num.get_n_leaves())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0acf1b",
   "metadata": {},
   "source": [
    "## Tasks 5-8: Encode Categorical Data & Train on Encoded Features\n",
    "We apply **OneHotEncoding** to categorical variables, retrain the Decision Tree, and optimize hyperparameters using `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f5d649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_enc Shape: (39073, 105)\n",
      "X_test_enc Shape: (9769, 105)\n",
      "Training Accuracy (Categorical): 0.999872034397154\n",
      "Testing Accuracy (Categorical): 0.8220902855972976\n",
      "Tree Depth: 53\n",
      "Number of Leaves: 5752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Select categorical features\n",
    "categorical_features = X_train.select_dtypes(include=['category', 'object']).columns\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Apply encoding\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "X_train_enc = preprocessor.fit_transform(X_train)\n",
    "X_test_enc = preprocessor.transform(X_test)\n",
    "\n",
    "# Check encoded shape\n",
    "print(\"X_train_enc Shape:\", X_train_enc.shape)\n",
    "print(\"X_test_enc Shape:\", X_test_enc.shape)\n",
    "\n",
    "# Train Decision Tree on Encoded Data\n",
    "clf_cat = DecisionTreeClassifier(random_state=42)\n",
    "clf_cat.fit(X_train_enc, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_accuracy_cat = accuracy_score(y_train, clf_cat.predict(X_train_enc))\n",
    "test_accuracy_cat = accuracy_score(y_test, clf_cat.predict(X_test_enc))\n",
    "\n",
    "# Print results\n",
    "print(\"Training Accuracy (Categorical):\", train_accuracy_cat)\n",
    "print(\"Testing Accuracy (Categorical):\", test_accuracy_cat)\n",
    "print(\"Tree Depth:\", clf_cat.get_depth())\n",
    "print(\"Number of Leaves:\", clf_cat.get_n_leaves())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb411dd",
   "metadata": {},
   "source": [
    "## Tasks 9-12: Hyperparameter Optimization\n",
    "We use `GridSearchCV` to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b298c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 10}\n",
      "Best Score: 0.8543751385306088\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=3, n_jobs=-1, return_train_score=True)\n",
    "grid_search.fit(X_train_enc, y_train)\n",
    "\n",
    "# Display best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa2262c",
   "metadata": {},
   "source": [
    "## Tasks 13-17: Final Model Evaluation & Table Comparisons\n",
    "We train the final Decision Tree using **optimal hyperparameters** and compare the results with `class2-output-only.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c68cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Training Accuracy: 0.8665830624728074\n",
      "Optimized Testing Accuracy: 0.8636503224485618\n",
      "Optimized Tree Depth: 10\n",
      "Optimized Number of Leaves: 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Your Model",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Reference Output",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "be24787c-17bb-4bd2-8bf5-a72e64d19b59",
       "rows": [
        [
         "0",
         "Training Accuracy",
         "0.8665830624728074",
         "0.8629"
        ],
        [
         "1",
         "Testing Accuracy",
         "0.8636503224485618",
         "0.8251"
        ],
        [
         "2",
         "Tree Depth",
         "10.0",
         "64.0"
        ],
        [
         "3",
         "Number of Leaves",
         "250.0",
         "7405.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Your Model</th>\n",
       "      <th>Reference Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training Accuracy</td>\n",
       "      <td>0.866583</td>\n",
       "      <td>0.8629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Testing Accuracy</td>\n",
       "      <td>0.863650</td>\n",
       "      <td>0.8251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tree Depth</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>64.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number of Leaves</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>7405.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric  Your Model  Reference Output\n",
       "0  Training Accuracy    0.866583            0.8629\n",
       "1   Testing Accuracy    0.863650            0.8251\n",
       "2         Tree Depth   10.000000           64.0000\n",
       "3   Number of Leaves  250.000000         7405.0000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train best model using best parameters\n",
    "clf_best = DecisionTreeClassifier(**grid_search.best_params_, random_state=42)\n",
    "clf_best.fit(X_train_enc, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_accuracy_best = accuracy_score(y_train, clf_best.predict(X_train_enc))\n",
    "test_accuracy_best = accuracy_score(y_test, clf_best.predict(X_test_enc))\n",
    "\n",
    "# Print results\n",
    "print(\"Optimized Training Accuracy:\", train_accuracy_best)\n",
    "print(\"Optimized Testing Accuracy:\", test_accuracy_best)\n",
    "print(\"Optimized Tree Depth:\", clf_best.get_depth())\n",
    "print(\"Optimized Number of Leaves:\", clf_best.get_n_leaves())\n",
    "\n",
    "# Compare with class2-output-only.ipynb\n",
    "comparison_data = {\n",
    "    \"Metric\": [\"Training Accuracy\", \"Testing Accuracy\", \"Tree Depth\", \"Number of Leaves\"],\n",
    "    \"Your Model\": [train_accuracy_best, test_accuracy_best, clf_best.get_depth(), clf_best.get_n_leaves()],\n",
    "    \"Reference Output\": [0.8629, 0.8251, 64, 7405]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "df_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66adb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7123e5e6",
   "metadata": {},
   "source": [
    "## Task 15: Train a Random Forest Classifier\n",
    "We now train a **RandomForestClassifier** and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "898fea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Accuracy: 0.9998464412765848\n",
      "Random Forest Testing Accuracy: 0.8584297266864571\n",
      "Random Forest Number of Trees: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train Random Forest\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(X_train_enc, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_accuracy_rf = accuracy_score(y_train, clf_rf.predict(X_train_enc))\n",
    "test_accuracy_rf = accuracy_score(y_test, clf_rf.predict(X_test_enc))\n",
    "\n",
    "# Print results\n",
    "print(\"Random Forest Training Accuracy:\", train_accuracy_rf)\n",
    "print(\"Random Forest Testing Accuracy:\", test_accuracy_rf)\n",
    "print(\"Random Forest Number of Trees:\", len(clf_rf.estimators_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e8a08",
   "metadata": {},
   "source": [
    "## Task 16: Train an AdaBoost Classifier\n",
    "We now train an **AdaBoostClassifier**, which is a boosting technique that improves weak learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee46ba5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/ml-algo/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Training Accuracy: 0.8641005297775958\n",
      "AdaBoost Testing Accuracy: 0.8732725969904801\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train AdaBoost\n",
    "clf_ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "clf_ada.fit(X_train_enc, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_accuracy_ada = accuracy_score(y_train, clf_ada.predict(X_train_enc))\n",
    "test_accuracy_ada = accuracy_score(y_test, clf_ada.predict(X_test_enc))\n",
    "\n",
    "# Print results\n",
    "print(\"AdaBoost Training Accuracy:\", train_accuracy_ada)\n",
    "print(\"AdaBoost Testing Accuracy:\", test_accuracy_ada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2fe1d9",
   "metadata": {},
   "source": [
    "## Task 17: Train a Gradient Boosting Classifier\n",
    "We now train a **GradientBoostingClassifier**, another boosting technique that reduces bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc8921b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Training Accuracy: 0.8670693317636219\n",
      "Gradient Boosting Testing Accuracy: 0.8722489507626164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train Gradient Boosting\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "clf_gb.fit(X_train_enc, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_accuracy_gb = accuracy_score(y_train, clf_gb.predict(X_train_enc))\n",
    "test_accuracy_gb = accuracy_score(y_test, clf_gb.predict(X_test_enc))\n",
    "\n",
    "# Print results\n",
    "print(\"Gradient Boosting Training Accuracy:\", train_accuracy_gb)\n",
    "print(\"Gradient Boosting Testing Accuracy:\", test_accuracy_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30584c7",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "We compare the performance of **Decision Tree, Random Forest, AdaBoost, and Gradient Boosting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f3ff407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7d6378a4-2f70-48ae-b937-1f1b0f57f187",
       "rows": [
        [
         "0",
         "Decision Tree",
         "0.8665830624728074",
         "0.8636503224485618"
        ],
        [
         "1",
         "Random Forest",
         "0.9998464412765848",
         "0.8584297266864571"
        ],
        [
         "2",
         "AdaBoost",
         "0.8641005297775958",
         "0.8732725969904801"
        ],
        [
         "3",
         "Gradient Boosting",
         "0.8670693317636219",
         "0.8722489507626164"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Testing Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.866583</td>\n",
       "      <td>0.863650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.858430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.864101</td>\n",
       "      <td>0.873273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.867069</td>\n",
       "      <td>0.872249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Training Accuracy  Testing Accuracy\n",
       "0      Decision Tree           0.866583          0.863650\n",
       "1      Random Forest           0.999846          0.858430\n",
       "2           AdaBoost           0.864101          0.873273\n",
       "3  Gradient Boosting           0.867069          0.872249"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a comparison table\n",
    "comparison_data = {\n",
    "    \"Model\": [\"Decision Tree\", \"Random Forest\", \"AdaBoost\", \"Gradient Boosting\"],\n",
    "    \"Training Accuracy\": [train_accuracy_best, train_accuracy_rf, train_accuracy_ada, train_accuracy_gb],\n",
    "    \"Testing Accuracy\": [test_accuracy_best, test_accuracy_rf, test_accuracy_ada, test_accuracy_gb],\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "df_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badfa834",
   "metadata": {},
   "source": [
    "✅ AdaBoost\n",
    "\n",
    "Best testing accuracy → 0.8733 (highest among all models)\n",
    "\n",
    "Balanced training accuracy → 0.8641 (not overfitting too much)\n",
    "\n",
    "Boosting method helps reduce bias and generalizes well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704a175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
